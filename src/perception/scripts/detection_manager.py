#!/usr/bin/python3
"""
æ£€æµ‹ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å¤šç§æ£€æµ‹API
æ”¯æŒGraspAnythingã€ReferringDinoç­‰æ£€æµ‹ç®—æ³•
"""

import rospy
import numpy as np
import threading
import time
import json
import cv2
from abc import ABC, abstractmethod
from sensor_msgs.msg import CompressedImage, Image
from perception.msg import (GraspDetection, GraspDetectionArray, 
                           GraspPose, TouchingPoint)
from geometry_msgs.msg import Point
from cv_bridge import CvBridge
from mmengine.config import Config
# from percept_dino_api_test import ReferingAPI  # ä½¿ç”¨HTTP APIæ›¿ä»£


class RateLimiter:
    """é¢‘ç‡é™åˆ¶å™¨"""
    
    def __init__(self, rate_hz):
        self.rate_hz = rate_hz
        self.min_interval = 1.0 / rate_hz if rate_hz > 0 else 0
        self.last_process_time = 0
    
    def can_process(self):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤„ç†ï¼ˆåŸºäºé¢‘ç‡é™åˆ¶ï¼‰"""
        current_time = time.time()
        if current_time - self.last_process_time >= self.min_interval:
            self.last_process_time = current_time
            return True
        return False
    
    def get_remaining_time(self):
        """è·å–å‰©ä½™ç­‰å¾…æ—¶é—´"""
        current_time = time.time()
        elapsed = current_time - self.last_process_time
        return max(0, self.min_interval - elapsed)


class BaseDetector(ABC):
    """æ£€æµ‹å™¨åŸºç±»"""
    
    def __init__(self, name, config):
        self.name = name
        self.config = config
        self.rate_limiter = RateLimiter(config.get('rate_hz', 1.0))
        self.enabled = config.get('enabled', True)
        self.bridge = CvBridge()
        
        if self.enabled:
            self._initialize()
            rospy.loginfo(f"ğŸ” æ£€æµ‹å™¨ {name} åˆå§‹åŒ–å®Œæˆ (é¢‘ç‡: {config.get('rate_hz', 1.0)}Hz)")
        else:
            rospy.loginfo(f"â¸ï¸ æ£€æµ‹å™¨ {name} å·²ç¦ç”¨")
    
    @abstractmethod
    def _initialize(self):
        """åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass
    
    @abstractmethod
    def _detect_impl(self, image, **kwargs):
        """å®é™…æ£€æµ‹é€»è¾‘ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass
    
    def detect(self, image, header=None, **kwargs):
        """ç»Ÿä¸€æ£€æµ‹æ¥å£"""
        if not self.enabled:
            return None
        
        if not self.rate_limiter.can_process():
            rospy.logdebug(f"æ£€æµ‹å™¨ {self.name} é¢‘ç‡é™åˆ¶ï¼Œè·³è¿‡æ­¤å¸§")
            return None
        
        try:
            start_time = time.time()
            result = self._detect_impl(image, **kwargs)
            detect_time = time.time() - start_time
            
            if result is not None:
                # è®¾ç½®æ¶ˆæ¯å¤´
                if hasattr(result, 'header') and header is not None:
                    result.header = header
                
                rospy.loginfo(f"æ£€æµ‹å™¨ {self.name} æ£€æµ‹å®Œæˆ: {detect_time:.2f}s")
            
            return result
            
        except Exception as e:
            rospy.logerr(f"æ£€æµ‹å™¨ {self.name} é”™è¯¯: {e}")
            return None


class GraspAnythingDetector(BaseDetector):
    """GraspAnythingæ£€æµ‹å™¨"""
    
    def _initialize(self):
        """åˆå§‹åŒ–GraspAnything API"""
        try:
            # åŠ¨æ€å¯¼å…¥ä»¥é¿å…ç¼ºå°‘ä¾èµ–æ—¶å´©æºƒ
            from percept_dino_api_test import GraspAnythingAPI
            
            # é…ç½®API
            cfg = Config()
            cfg.server_list = self.config.get('endpoint', 
                '/home/agilex/MobileManipulator/src/perception/scripts/server_grasp.json')
            cfg.model_name = self.config.get('model_name', 'full')
            
            self.api = GraspAnythingAPI(cfg)
            self.use_touching_points = self.config.get('use_touching_points', True)
            self.visualize = self.config.get('visualize', False)
            
            rospy.loginfo(f"âœ… GraspAnything API åˆå§‹åŒ–æˆåŠŸ")
            rospy.loginfo(f"  æ¨¡å‹: {cfg.model_name}")
            rospy.loginfo(f"  æ¥è§¦ç‚¹: {self.use_touching_points}")
            
        except ImportError as e:
            rospy.logerr(f"âŒ æ— æ³•å¯¼å…¥GraspAnything API: {e}")
            self.enabled = False
        except Exception as e:
            rospy.logerr(f"âŒ GraspAnything API åˆå§‹åŒ–å¤±è´¥: {e}")
            self.enabled = False
    
    def _detect_impl(self, image, **kwargs):
        """GraspAnythingæ£€æµ‹å®ç°"""
        if not hasattr(self, 'api'):
            return None
        
        try:
            # è°ƒç”¨API
            objs, padded_img = self.api.forward(
                rgb=image,
                use_touching_points=self.use_touching_points
            )
            
            # è½¬æ¢ä¸ºROSæ¶ˆæ¯
            grasp_msg = GraspDetectionArray()
            grasp_msg.header.stamp = rospy.Time.now()
            
            # å¤„ç†æ¯ä¸ªæ£€æµ‹åˆ°çš„å¯¹è±¡
            for obj in objs[0]:  # objsæ˜¯[[obj1, obj2, ...]]æ ¼å¼
                grasp_det = self._create_grasp_detection(obj)
                grasp_msg.detections.append(grasp_det)
            
            # å¯é€‰ï¼šç”Ÿæˆå¯è§†åŒ–å›¾åƒ
            vis_image = None
            if self.visualize and len(objs[0]) > 0:
                vis_image = self.api.vis(objs, image, padded_img, 
                                       img_fp='', to_save=False)
            
            return {
                'detections': grasp_msg,
                'vis_image': vis_image,
                'num_objects': len(grasp_msg.detections)
            }
            
        except Exception as e:
            rospy.logerr(f"GraspAnythingæ£€æµ‹å¤±è´¥: {e}")
            return None
    
    def _create_grasp_detection(self, obj):
        """å°†APIå¯¹è±¡è½¬æ¢ä¸ºROSæ¶ˆæ¯"""
        det = GraspDetection()
        
        # è¾¹ç•Œæ¡†
        det.bbox = obj['dt_bbox']
        
        # æ£€æµ‹ç½®ä¿¡åº¦
        det.score = obj.get('dt_score', 0.5)
        
        # RLEæ©ç 
        if 'dt_rle' in obj:
            det.rle = json.dumps(obj['dt_rle'])
        
        # åˆ†å‰²æ©ç ï¼ˆå‹ç¼©å­˜å‚¨ï¼‰
        if 'dt_mask' in obj:
            mask = obj['dt_mask'].astype(np.uint8) * 255
            _, compressed = cv2.imencode('.png', mask)
            mask_msg = CompressedImage()
            mask_msg.format = "png"
            mask_msg.data = compressed.tobytes()
            det.mask = mask_msg
        
        # Reidç‰¹å¾
        if 'reid_fea' in obj:
            det.reid_feature = obj['reid_fea']
        
        # æŠ“å–å§¿æ€
        if 'affs' in obj and 'scores' in obj:
            for aff, score in zip(obj['affs'], obj['scores']):
                pose = GraspPose()
                pose.x = aff[0]
                pose.y = aff[1] 
                pose.width = aff[2]
                pose.height = aff[3]
                pose.theta = aff[4]
                pose.confidence = score
                det.grasp_poses.append(pose)
        
        # æ¥è§¦ç‚¹
        if 'touching_points' in obj:
            for tp_pair in obj['touching_points']:
                tp = TouchingPoint()
                tp.point1 = Point(x=tp_pair[0][0], y=tp_pair[0][1], z=0)
                tp.point2 = Point(x=tp_pair[1][0], y=tp_pair[1][1], z=0)
                det.touching_points.append(tp)
        
        return det


class ReferringDetector(BaseDetector):
    """Referring DINOæ£€æµ‹å™¨ï¼ˆä½¿ç”¨çœŸå®DDSäº‘APIï¼‰"""
    
    def _initialize(self):
        """åˆå§‹åŒ–Referring DINOçœŸå®API"""
        try:
            # åŠ¨æ€å¯¼å…¥ä»¥é¿å…ç¼ºå°‘ä¾èµ–æ—¶å´©æºƒ
            from percept_dino_api_test import ReferingAPI
            from mmengine.config import Config
            
            rospy.loginfo(f"ğŸ” ReferringDetector åˆå§‹åŒ– (DDSäº‘API)")
            
            # é…ç½®çœŸå®çš„DDSäº‘API
            cfg = Config()
            cfg.uri = r'/v2/task/dino_xseek/detection'
            cfg.status_uri = r'/v2/task_status'
            cfg.token = 'c4cdacb48bc4d1a1a335c88598a18e8c'  # ä½¿ç”¨percept_dino_api_test.pyä¸­çš„token
            
            self.api = ReferingAPI(cfg)
            self.default_query = self.config.get('default_query', 'ç‰©ä½“')
            
            rospy.loginfo(f"  âœ… DDSäº‘APIåˆå§‹åŒ–æˆåŠŸ")
            rospy.loginfo(f"  Token: {cfg.token[:8]}...")
            rospy.loginfo(f"  é»˜è®¤æŸ¥è¯¢: {self.default_query}")
            
        except ImportError as e:
            rospy.logerr(f"âŒ æ— æ³•å¯¼å…¥ReferingAPI: {e}")
            rospy.logerr("è¯·ç¡®ä¿percept_dino_api_test.pyå’Œç›¸å…³ä¾èµ–å¯ç”¨")
            self.enabled = False
        except Exception as e:
            rospy.logerr(f"âŒ ReferringDetector APIåˆå§‹åŒ–å¤±è´¥: {e}")
            self.enabled = False
    
    def _detect_impl(self, image, text_query=None, **kwargs):
        """Referringæ£€æµ‹å®ç°ï¼ˆä½¿ç”¨çœŸå®DDSäº‘APIï¼‰"""
        if not hasattr(self, 'api'):
            rospy.logwarn("ReferringDetector APIæœªåˆå§‹åŒ–")
            return None
            
        # ä½¿ç”¨é»˜è®¤æŸ¥è¯¢æˆ–ä¼ å…¥çš„æŸ¥è¯¢
        query = text_query or self.default_query
        
        rospy.loginfo(f"ReferringDetector DDSæ£€æµ‹: query='{query}', å›¾åƒå°ºå¯¸={image.shape}")
        
        try:
            # è°ƒç”¨çœŸå®çš„DDSäº‘API
            task = self.api.forward(rgb=image, text=query)
            api_result = task.result if hasattr(task, 'result') else {}
            
            rospy.loginfo(f"DDS APIè¿”å›ç»“æœ: {api_result}")
            
            # åˆ›å»ºæ£€æµ‹ç»“æœ
            grasp_msg = GraspDetectionArray()
            grasp_msg.header.stamp = rospy.Time.now()
            
            # è§£æAPIç»“æœ - DDS APIè¿”å›æ ¼å¼: {'objects': [{'bbox': [x1, y1, x2, y2]}]}
            if 'objects' in api_result and len(api_result['objects']) > 0:
                for obj in api_result['objects']:
                    if 'bbox' in obj:
                        det = GraspDetection()
                        
                        # DDS APIè¿”å›çš„bboxæ ¼å¼: [x1, y1, x2, y2] 
                        bbox = obj['bbox']
                        det.bbox = [
                            int(bbox[0]),                    # x
                            int(bbox[1]),                    # y
                            int(bbox[2] - bbox[0]),         # width
                            int(bbox[3] - bbox[1])          # height
                        ]
                        
                        # æ£€æµ‹ç½®ä¿¡åº¦ï¼ˆDDS APIå¯èƒ½ä¸è¿”å›ç½®ä¿¡åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
                        det.score = obj.get('confidence', 0.8)
                        
                        # ä¸ºreferringæ£€æµ‹ç”Ÿæˆç®€å•çš„æŠ“å–å§¿æ€ï¼ˆåœ¨è¾¹ç•Œæ¡†ä¸­å¿ƒï¼‰
                        center_x = int((bbox[0] + bbox[2]) / 2)
                        center_y = int((bbox[1] + bbox[3]) / 2)
                        
                        pose = GraspPose()
                        pose.x = center_x
                        pose.y = center_y
                        pose.width = min(det.bbox[2], det.bbox[3]) * 0.8  # 80%çš„è¾¹ç•Œæ¡†å°ºå¯¸
                        pose.height = 30  # å›ºå®šé«˜åº¦
                        pose.theta = 0  # æ°´å¹³æ–¹å‘
                        pose.confidence = det.score
                        det.grasp_poses.append(pose)
                        
                        grasp_msg.detections.append(det)
                        
                        # æ·»åŠ nameå±æ€§ä»¥å…¼å®¹åç»­å¤„ç†
                        det.name = f"object_{len(grasp_msg.detections)}"
                        
                        rospy.loginfo(f"  æ£€æµ‹åˆ°å¯¹è±¡: bbox={det.bbox}, score={det.score:.3f}")
            
            else:
                rospy.loginfo(f"ReferringDetector: DDS APIæ²¡æœ‰æ£€æµ‹åˆ° '{query}'")
            
            # åˆ›å»ºå¯è§†åŒ–ï¼ˆå³ä½¿æ²¡æœ‰æ£€æµ‹åˆ°å¯¹è±¡ä¹Ÿåˆ›å»ºï¼‰
            vis_image = None
            if self.config.get('visualize', False):
                vis_image = image.copy()
                
                if len(grasp_msg.detections) > 0:
                    # æœ‰æ£€æµ‹ç»“æœæ—¶ç»˜åˆ¶è¾¹ç•Œæ¡†å’ŒæŠ“å–ç‚¹
                    for det in grasp_msg.detections:
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        cv2.rectangle(vis_image, 
                                     (det.bbox[0], det.bbox[1]),
                                     (det.bbox[0] + det.bbox[2], det.bbox[1] + det.bbox[3]),
                                     (0, 255, 255), 3)  # é»„è‰²è¾¹æ¡†è¡¨ç¤ºReferringæ£€æµ‹
                        
                        # æ·»åŠ æ–‡æœ¬
                        cv2.putText(vis_image, f"Referring: '{query}'", 
                                   (det.bbox[0], det.bbox[1] - 10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
                        
                        # ç»˜åˆ¶æŠ“å–ç‚¹
                        for pose in det.grasp_poses:
                            cv2.circle(vis_image, (int(pose.x), int(pose.y)), 5, (255, 255, 0), -1)
                            cv2.circle(vis_image, (int(pose.x), int(pose.y)), 8, (0, 255, 255), 2)
                else:
                    # æ²¡æœ‰æ£€æµ‹ç»“æœæ—¶æ˜¾ç¤ºæŸ¥è¯¢ä¿¡æ¯
                    h, w = vis_image.shape[:2]
                    cv2.putText(vis_image, f"Referring Query: '{query}' - No objects found", 
                               (10, h - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            return {
                'detections': grasp_msg,
                'vis_image': vis_image,
                'num_objects': len(grasp_msg.detections)
            }
            
        except Exception as e:
            rospy.logerr(f"ReferringDetector DDS APIè°ƒç”¨å¤±è´¥: {e}")
            import traceback
            if rospy.get_param('/unified_perception/debug_mode', False):
                traceback.print_exc()
                
            # è¿”å›ç©ºç»“æœ
            grasp_msg = GraspDetectionArray()
            grasp_msg.header.stamp = rospy.Time.now()
            return {
                'detections': grasp_msg,
                'vis_image': None,
                'num_objects': 0
            }


class DetectionManager:
    """æ£€æµ‹ç®¡ç†å™¨ - ç®¡ç†æ‰€æœ‰æ£€æµ‹å™¨"""
    
    def __init__(self, detection_configs):
        self.detectors = {}
        
        # åˆå§‹åŒ–å„ç§æ£€æµ‹å™¨
        for api_name, config in detection_configs.items():
            if config.get('enabled', False):
                try:
                    if api_name == 'grasp_anything':
                        self.detectors[api_name] = GraspAnythingDetector(api_name, config)
                    elif api_name == 'referring_dino':
                        self.detectors[api_name] = ReferringDetector(api_name, config)
                    else:
                        rospy.logwarn(f"æœªçŸ¥æ£€æµ‹å™¨ç±»å‹: {api_name}")
                        
                except Exception as e:
                    rospy.logerr(f"æ£€æµ‹å™¨ {api_name} åˆå§‹åŒ–å¤±è´¥: {e}")
            else:
                rospy.loginfo(f"â¸ï¸ æ£€æµ‹å™¨ {api_name} å·²ç¦ç”¨")
        
        rospy.loginfo(f"ğŸ” æ£€æµ‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ´»è·ƒæ£€æµ‹å™¨: {list(self.detectors.keys())}")
    
    def get_detector(self, detector_name):
        """è·å–æŒ‡å®šæ£€æµ‹å™¨"""
        if detector_name in self.detectors:
            return self.detectors[detector_name]
        else:
            raise ValueError(f"Detector {detector_name} not found or not enabled")
    
    def get_active_detectors(self):
        """è·å–æ‰€æœ‰æ´»è·ƒæ£€æµ‹å™¨åç§°"""
        return list(self.detectors.keys())
    
    def detect_all(self, image, header=None):
        """ä½¿ç”¨æ‰€æœ‰æ´»è·ƒæ£€æµ‹å™¨è¿›è¡Œæ£€æµ‹"""
        results = {}
        
        for name, detector in self.detectors.items():
            if detector.enabled:
                result = detector.detect(image, header)
                results[name] = result
        
        return results


class VisualizationPublisher:
    """å¯è§†åŒ–å‘å¸ƒå™¨"""
    
    def __init__(self, vis_topics):
        self.bridge = CvBridge()
        self.publishers = {}
        
        # åˆ›å»ºå¯è§†åŒ–å‘å¸ƒå™¨
        for topic_name, topic_path in vis_topics.items():
            if topic_path:
                if 'compressed' in topic_name.lower():
                    self.publishers[topic_name] = rospy.Publisher(
                        topic_path, CompressedImage, queue_size=1
                    )
                else:
                    self.publishers[topic_name] = rospy.Publisher(
                        topic_path, Image, queue_size=1
                    )
    
    def publish_visualization(self, image, header, topics_to_publish):
        """å‘å¸ƒå¯è§†åŒ–å›¾åƒ"""
        if image is None:
            return
        
        for topic_name in topics_to_publish:
            if topic_name in self.publishers:
                try:
                    if 'compressed' in topic_name.lower():
                        # å‘å¸ƒå‹ç¼©å›¾åƒ
                        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 80]
                        _, compressed = cv2.imencode('.jpg', image, encode_param)
                        
                        compressed_msg = CompressedImage()
                        compressed_msg.header = header
                        compressed_msg.format = "jpeg"
                        compressed_msg.data = compressed.tobytes()
                        self.publishers[topic_name].publish(compressed_msg)
                    else:
                        # å‘å¸ƒåŸå§‹å›¾åƒ
                        raw_msg = self.bridge.cv2_to_imgmsg(image, "bgr8")
                        raw_msg.header = header
                        self.publishers[topic_name].publish(raw_msg)
                        
                except Exception as e:
                    rospy.logerr(f"å¯è§†åŒ–å‘å¸ƒå¤±è´¥ {topic_name}: {e}")


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    rospy.init_node('detection_manager_test')
    
    # æµ‹è¯•é…ç½®
    test_config = {
        'grasp_anything': {
            'endpoint': '/home/agilex/MobileManipulator/src/perception/scripts/server_grasp.json',
            'model_name': 'full',
            'rate_hz': 0.5,
            'use_touching_points': True,
            'visualize': True,
            'enabled': True
        },
        'referring_dino': {
            'endpoint': 'http://localhost:5000/referring',
            'model_name': 'dino', 
            'rate_hz': 1.0,
            'enabled': False
        }
    }
    
    try:
        manager = DetectionManager(test_config)
        
        # è·å–GraspAnythingæ£€æµ‹å™¨
        grasp_detector = manager.get_detector('grasp_anything')
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒï¼ˆçº¯è‰²å›¾åƒï¼‰
        test_image = np.ones((480, 640, 3), dtype=np.uint8) * 128
        
        rospy.loginfo("å¼€å§‹æ£€æµ‹æµ‹è¯•...")
        
        rate = rospy.Rate(0.2)  # 0.2Hzæµ‹è¯•
        while not rospy.is_shutdown():
            result = grasp_detector.detect(test_image)
            
            if result:
                rospy.loginfo(f"æ£€æµ‹ç»“æœ: {result['num_objects']} ä¸ªå¯¹è±¡")
            else:
                rospy.loginfo("æ£€æµ‹å™¨æš‚ä¸å¯ç”¨æˆ–é¢‘ç‡å—é™")
            
            rate.sleep()
            
    except rospy.ROSInterruptException:
        pass
    except Exception as e:
        rospy.logerr(f"æµ‹è¯•å¤±è´¥: {e}")
